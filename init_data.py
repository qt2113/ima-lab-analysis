#!/usr/bin/env python3
"""
æ•°æ®åˆå§‹åŒ–è„šæœ¬ - é¦–æ¬¡è¿è¡Œæ—¶åŠ è½½æ•°æ®åˆ°æ•°æ®åº“
"""
import sys
import pandas as pd
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from data.database import db
from data.loaders.historical_loader import load_historical_data
from data.loaders.realtime_loader import load_realtime_data


def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“å¹¶åŠ è½½æ•°æ®"""
    print("=" * 60)
    print("IMA Lab æ•°æ®åˆå§‹åŒ–")
    print("=" * 60)
    
    # 1. åŠ è½½å†å²æ•°æ®
    print("\n[1/2] æ­£åœ¨åŠ è½½å†å²æ•°æ®...")
    try:
        df_historical = load_historical_data()
        db.insert_data(df_historical, source='historical', replace=True)
        print(f"âœ… å†å²æ•°æ®åŠ è½½æˆåŠŸï¼š{len(df_historical)} æ¡è®°å½•")
    except FileNotFoundError as e:
        print(f"âš ï¸ å†å²æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè·³è¿‡: {e}")
        df_historical = None
    except Exception as e:
        print(f"âŒ å†å²æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 2. åŠ è½½å®æ—¶æ•°æ®
    print("\n[2/2] æ­£åœ¨ä»Google Sheetsæ‹‰å–å®æ—¶æ•°æ®...")
    try:
        df_realtime = load_realtime_data()
        if not df_realtime.empty:
            # å†å²æ•°æ® vs å®æ—¶æ•°æ®å»é‡ï¼ˆä»¥å†å²ä¸ºå‡†ï¼‰
            if df_historical is not None and not df_historical.empty:
                df_historical['Start'] = pd.to_datetime(df_historical['Start'], errors='coerce')
                df_realtime['Start'] = pd.to_datetime(df_realtime['Start'], errors='coerce')
                
                # ç§’çº§ç²¾ç¡®åŒ¹é…ï¼ˆä¿ç•™å¤‡ç”¨ï¼‰
                # hist_keys = set(zip(df_historical['Start'], df_historical['item name(with num)']))
                
                # åˆ†é’Ÿçº§åŒ¹é…ï¼ˆå»é™¤æ¯«ç§’ååŒ¹é…ï¼Œè¯¯å·®1åˆ†é’Ÿå†…ç®—åŒä¸€æ¡ï¼‰
                df_historical['Start_min'] = df_historical['Start'].dt.floor('min')
                df_realtime['Start_min'] = df_realtime['Start'].dt.floor('min')
                hist_keys = set(zip(df_historical['Start_min'], df_historical['item name(with num)']))
                
                original_count = len(df_realtime)
                df_realtime = df_realtime[
                    ~df_realtime.apply(lambda x: (x['Start_min'], x['item name(with num)']) in hist_keys, axis=1)
                ]
                removed_count = original_count - len(df_realtime)
                if removed_count > 0:
                    print(f"ğŸ—‘ï¸  å»é™¤ {removed_count} æ¡ä¸å†å²é‡å¤çš„å®æ—¶æ•°æ®")
                
                # å»é™¤ä¸´æ—¶åˆ—ï¼Œé¿å…æ’å…¥æ•°æ®åº“æ—¶æŠ¥é”™
                df_realtime = df_realtime.drop(columns=['Start_min'], errors='ignore')
            
            db.insert_data(df_realtime, source='realtime', replace=True)
            print(f"âœ… å®æ—¶æ•°æ®åŠ è½½æˆåŠŸï¼š{len(df_realtime)} æ¡è®°å½•")
        else:
            print("âš ï¸ æœªæ‹‰å–åˆ°å®æ—¶æ•°æ®")
    except Exception as e:
        print(f"âŒ å®æ—¶æ•°æ®åŠ è½½å¤±è´¥: {e}")
        print("æç¤ºï¼šè¯·æ£€æŸ¥Google Service Accounté…ç½®")
        return False
    
    # 3. æ˜¾ç¤ºç»Ÿè®¡
    print("\n" + "=" * 60)
    print("æ•°æ®åº“ç»Ÿè®¡")
    print("=" * 60)
    stats = db.get_statistics()
    print(f"æ€»è®°å½•æ•°: {stats['total_records']}")
    print("\nå„æ•°æ®æºè®°å½•æ•°:")
    for source, count in stats.get('by_source', {}).items():
        print(f"  - {source}: {count}")
    
    print("\nTop 10 ç±»åˆ«:")
    for category, count in list(stats.get('top_categories', {}).items())[:10]:
        print(f"  - {category}: {count}")
    
    print("\nâœ… æ•°æ®åˆå§‹åŒ–å®Œæˆï¼")
    print("=" * 60)
    
    return True


if __name__ == '__main__':
    success = init_database()
    sys.exit(0 if success else 1)
