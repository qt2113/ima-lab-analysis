"""
å®æ—¶æ•°æ®åŠ è½½å™¨ - ä»Google Sheetsæ‹‰å–å®æ—¶å€Ÿç”¨è®°å½•
"""
import pandas as pd
import re
import gspread
from google.oauth2.service_account import Credentials

from config.settings import GOOGLE_SHEET_ID, TARGET_SHEETS
from config.auth import GoogleAuthConfig
from data.loaders.category_mapper import mapper


class RealtimeDataLoader:
    """å®æ—¶æ•°æ®åŠ è½½å™¨"""
    
    @staticmethod
    def _strip_number(item_name: str) -> str:
        """å»é™¤ç‰©å“åç§°æœ«å°¾çš„ç¼–å·"""
        if pd.isna(item_name):
            return ""
        return re.sub(r'\s+\d+$', '', str(item_name)).strip()
    
    def _connect_google_sheets(self) -> gspread.Client:
        """å»ºç«‹Google Sheetsè¿æ¥"""
        service_account_info = GoogleAuthConfig.get_service_account_info()
        scopes = GoogleAuthConfig.get_scopes()
        
        credentials = Credentials.from_service_account_info(
            service_account_info,
            scopes=scopes
        )
        
        return gspread.authorize(credentials)
    
    def _fetch_sheet_data(self, sheet_name: str) -> pd.DataFrame:
        """
        ä»æŒ‡å®šSheetæ‹‰å–æ•°æ®
        
        Args:
            sheet_name: Sheetåç§°
            
        Returns:
            åŸå§‹æ•°æ®DataFrame
        """
        try:
            client = self._connect_google_sheets()
            workbook = client.open_by_key(GOOGLE_SHEET_ID)
            
            # æŸ¥æ‰¾ç›®æ ‡Sheet
            target_sheet = None
            for sheet in workbook.worksheets():
                if sheet.title == sheet_name:
                    target_sheet = sheet
                    break
            
            if not target_sheet:
                print(f"âš ï¸ æœªæ‰¾åˆ°Sheet: {sheet_name}")
                return pd.DataFrame()
            
            # è·å–æ•°æ®
            data = target_sheet.get_all_records()
            df = pd.DataFrame(data)
            df['sheet_source'] = sheet_name
            
            print(f"âœ… ä» {sheet_name} æ‹‰å– {len(df)} è¡ŒåŸå§‹æ•°æ®")
            return df
            
        except Exception as e:
            print(f"âŒ æ‹‰å– {sheet_name} å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _clean_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…ç†å’Œæ ‡å‡†åŒ–åˆ—å"""
        # æ¸…ç†åˆ—å
        df.columns = [str(col).strip() for col in df.columns]
        
        # ä¿®å¤å¸¸è§çš„åˆ—åé—®é¢˜
        column_fixes = {}
        
        # ä¿®å¤ç¬¬ä¸€åˆ—ï¼ˆé€šå¸¸æ˜¯NetIDï¼‰
        if len(df.columns) > 0 and ('Unnamed:' in df.columns[0] or df.columns[0] == ''):
            column_fixes[df.columns[0]] = 'NetID'
        
        # ä¿®å¤Equipment Nameåˆ—
        for col in df.columns:
            if 'Equipment Name' in col:
                column_fixes[col] = 'Equipment Name'
        
        if column_fixes:
            df = df.rename(columns=column_fixes)
        
        return df
    
    def _validate_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        required_cols = ['Time', 'NetID', 'Equipment Name', 'Code', 'Action']
        
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        
        # åˆ é™¤å…³é”®åˆ—ä¸ºç©ºçš„è¡Œ
        df = df.dropna(subset=required_cols).copy()
        
        # è½¬æ¢æ—¶é—´åˆ—
        df['Time'] = pd.to_datetime(
            df['Time'], 
            format='%m/%d/%Y %H:%M:%S', 
            errors='coerce'
        )
        
        return df
    
    def _map_category(self, row: pd.Series) -> str:
        """
        æ˜ å°„Categoryï¼ˆå…ˆå°è¯•Codeï¼Œå†å°è¯•Nameï¼‰
        
        Args:
            row: æ•°æ®è¡Œ
            
        Returns:
            Categoryåç§°
        """
        code = str(row['Code']).strip()
        name_with_num = str(row['Equipment Name']).strip()
        name_stripped = self._strip_number(name_with_num)
        
        # ä½¿ç”¨ç»Ÿä¸€çš„mapper
        return mapper.get_category(code=code, name=name_stripped)
    
    def _process_borrow_records(self, group: pd.DataFrame) -> pd.DataFrame:
        """
        å¤„ç†å•ä¸ªç‰©å“çš„å€Ÿè¿˜è®°å½•
        
        Args:
            group: å•ä¸ªç‰©å“çš„æ‰€æœ‰æ“ä½œè®°å½•
            
        Returns:
            å€Ÿç”¨è®°å½•DataFrame
        """
        # ç­›é€‰æœ‰æ•ˆæ“ä½œ
        valid_actions = group[
            group['Action'].isin(['Check Out', 'Check In'])
        ].sort_values('Time').reset_index(drop=True)
        
        if valid_actions.empty:
            return pd.DataFrame()
        
        records = []
        check_outs = valid_actions[valid_actions['Action'] == 'Check Out'].copy()
        check_ins = valid_actions[valid_actions['Action'] == 'Check In'].copy()
        
        # åŒ¹é…Check Outå’ŒCheck In
        for _, co_row in check_outs.iterrows():
            # æŸ¥æ‰¾å¯¹åº”çš„Check In
            potential_ci = check_ins[check_ins['Time'] > co_row['Time']]
            
            if not potential_ci.empty:
                ci_row = potential_ci.iloc[0]
                
                # è®¡ç®—æ—¶é•¿
                time_diff = ci_row['Time'] - co_row['Time']
                duration_hours = time_diff.total_seconds() / 3600
                
                records.append({
                    'Start': co_row['Time'],
                    'finished': ci_row['Time'],
                    'duration (hours)': round(duration_hours, 0),
                    'item name(with num)': co_row['Equipment Name'],
                    'Category': co_row['Category'],
                    'source': 'realtime',
                    'sheet_source': co_row['sheet_source']
                })
                
                # ç§»é™¤å·²åŒ¹é…çš„Check In
                check_ins = check_ins[check_ins['Time'] != ci_row['Time']]
            else:
                # æœªå½’è¿˜çš„è®°å½•ï¼ˆå½“å‰å€Ÿå‡ºçŠ¶æ€ï¼‰
                records.append({
                    'Start': co_row['Time'],
                    'finished': pd.NaT,
                    'duration (hours)': None,
                    'item name(with num)': co_row['Equipment Name'],
                    'Category': co_row['Category'],
                    'source': 'realtime',
                    'sheet_source': co_row['sheet_source']
                })
        
        return pd.DataFrame(records)
    
    def load(self, sheet_names: list = None) -> pd.DataFrame:
        """
        åŠ è½½å®æ—¶æ•°æ®
        
        Args:
            sheet_names: è¦æ‹‰å–çš„Sheetåç§°åˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„TARGET_SHEETS
            
        Returns:
            æ¸…æ´—åçš„DataFrame
        """
        if sheet_names is None:
            sheet_names = TARGET_SHEETS
        
        print(f"ğŸŒ å¼€å§‹ä»Google Sheetsæ‹‰å–å®æ—¶æ•°æ®...")
        
        all_data = []
        
        # æ‹‰å–å„ä¸ªSheet
        for sheet_name in sheet_names:
            df_sheet = self._fetch_sheet_data(sheet_name)
            if not df_sheet.empty:
                all_data.append(df_sheet)
        
        if not all_data:
            print("âš ï¸ æœªæ‹‰å–åˆ°ä»»ä½•æ•°æ®")
            return pd.DataFrame()
        
        # åˆå¹¶æ‰€æœ‰Sheetæ•°æ®
        df_raw = pd.concat(all_data, ignore_index=True)
        print(f"ğŸ“Š å…±æ‹‰å– {len(df_raw)} è¡ŒåŸå§‹æ•°æ®")
        
        # æ¸…ç†å’ŒéªŒè¯
        df_raw = self._clean_columns(df_raw)
        df_raw = self._validate_data(df_raw)
        
        # æ˜ å°„Category
        df_raw['Category'] = df_raw.apply(self._map_category, axis=1)
        
        # å¤„ç†å€Ÿç”¨è®°å½•ï¼ˆæŒ‰ç‰©å“åˆ†ç»„ï¼‰
        df_unified = df_raw.groupby(
            ['NetID', 'Equipment Name'], 
            group_keys=False
        ).apply(self._process_borrow_records).reset_index(drop=True)
        
        if df_unified.empty:
            print("âš ï¸ æœªç”Ÿæˆæœ‰æ•ˆçš„å€Ÿç”¨è®°å½•")
            return pd.DataFrame()
        
        # ç”Ÿæˆä¸å¸¦ç¼–å·çš„ç‰©å“åç§°
        df_unified['item name'] = df_unified['item name(with num)'].apply(
            self._strip_number
        )
        
        # å››èˆäº”å…¥duration
        if 'duration (hours)' in df_unified.columns:
            df_unified['duration (hours)'] = (
                pd.to_numeric(df_unified['duration (hours)'], errors='coerce')
                .round(0)
                .astype('Int64')
            )
        
        print(f"âœ… æˆåŠŸå¤„ç† {len(df_unified)} æ¡å€Ÿç”¨è®°å½•")
        
        return df_unified


# ä¾¿æ·å‡½æ•°
def load_realtime_data(sheet_names: list = None) -> pd.DataFrame:
    """åŠ è½½å®æ—¶æ•°æ®çš„å¿«æ·å‡½æ•°"""
    loader = RealtimeDataLoader()
    return loader.load(sheet_names)
