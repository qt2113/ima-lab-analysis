"""
å†å²æ•°æ®åŠ è½½å™¨ - ä»Excelæ–‡ä»¶åŠ è½½å†å²å€Ÿç”¨è®°å½•
"""
import pandas as pd
import re
from pathlib import Path

from config.settings import HISTORICAL_DATA_FILES
from data.loaders.category_mapper import mapper


class HistoricalDataLoader:
    """å†å²æ•°æ®åŠ è½½å™¨"""
    
    # åŸå§‹åˆ—ååˆ°æ ‡å‡†åˆ—åçš„æ˜ å°„
    COLUMN_MAPPING = {
        'started': 'Start',
        'finished': 'finished',
        'duration (hours)': 'duration (hours)',
        'item category': 'Category',
        'name': 'item name(with num)'
    }
    
    @staticmethod
    def _strip_number(item_name: str) -> str:
        """å»é™¤ç‰©å“åç§°æœ«å°¾çš„ç¼–å·"""
        if pd.isna(item_name):
            return ""
        # ç§»é™¤æœ«å°¾çš„ç©ºæ ¼å’Œæ•°å­—
        return re.sub(r'\s+\d+$', '', str(item_name)).strip()
    
    def load(self, file_paths: list = None) -> pd.DataFrame:
        """
        åŠ è½½å†å²æ•°æ®
        
        Args:
            file_paths: Excelæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„
            
        Returns:
            æ¸…æ´—åçš„DataFrame
        """
        if file_paths is None:
            file_paths = HISTORICAL_DATA_FILES
        
        all_dfs = []
        
        for file_path in file_paths:
            file_path = Path(file_path.strip())
            
            if not file_path.exists():
                print(f"âš ï¸ è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶: {file_path}")
                continue
            
            print(f"ğŸ“‚ æ­£åœ¨åŠ è½½å†å²æ•°æ®: {file_path}")
            
            df = pd.read_excel(file_path, engine='openpyxl')
            
            df = df[list(self.COLUMN_MAPPING.keys())].rename(columns=self.COLUMN_MAPPING)
            
            df['item name'] = df['item name(with num)'].apply(self._strip_number)
            
            df['source'] = 'historical'
            df['sheet_source'] = file_path.stem
            
            df = df.dropna(subset=['Start', 'Category']).reset_index(drop=True)
            
            df['Category'] = df['Category'].astype(str)
            
            if 'duration (hours)' in df.columns:
                df['duration (hours)'] = (
                    pd.to_numeric(df['duration (hours)'], errors='coerce')
                    .round(0)
                    .astype('Int64')
                )
            
            all_dfs.append(df)
            print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è®°å½• from {file_path.name}")
        
        if not all_dfs:
            raise FileNotFoundError("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å†å²æ•°æ®æ–‡ä»¶")
        
        result_df = pd.concat(all_dfs, ignore_index=True)
        result_df = result_df.drop_duplicates(subset=['Start', 'item name(with num)'], keep='first')
        print(f"âœ… å…±åŠ è½½ {len(result_df)} æ¡å†å²è®°å½•ï¼ˆå»é‡åï¼‰")
        
        return result_df


# ä¾¿æ·å‡½æ•°
def load_historical_data(file_paths: list = None) -> pd.DataFrame:
    """åŠ è½½å†å²æ•°æ®çš„å¿«æ·å‡½æ•°"""
    loader = HistoricalDataLoader()
    return loader.load(file_paths)
